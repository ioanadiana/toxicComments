Python scripts for ToxicComments Kaggle Competition - ranking top 10%


Method -  Ensemble ( LSTM_Glove + LSTM_Fasttext + LogisticRegression_Ngram + baseline_output)

Glove Dataset - glove.840B.300d.zip: https://nlp.stanford.edu/projects/glove/ 
Fasttext Dataset - crawl-300d-2M.vec.zip: https://fasttext.cc/docs/en/english-vectors.html

Next steps:
1. using larger Glove and Fasttext datasets will have a significant imporvement
2. Fine-tuning the hyperparameters for each models
3. Trying Random Forest or CNN
